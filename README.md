<!--
<p align="center">
  <img src="./assets/sapiens_animation.gif" alt="Sapiens" title="Sapiens" width="500"/>
</p>

<p align="center">
   <h2 align="center">Foundation for Human Vision Models</h2>
   <p align="center">
      <a href="https://rawalkhirodkar.github.io/"><strong>Rawal Khirodkar</strong></a>
      Â·
      <a href="https://scholar.google.ch/citations?user=oLi7xJ0AAAAJ&hl=en"><strong>Timur Bagautdinov</strong></a>
      Â·
      <a href="https://una-dinosauria.github.io/"><strong>Julieta Martinez</strong></a>
      Â·
      <a href="https://about.meta.com/realitylabs/"><strong>Su Zhaoen</strong></a>
      Â·
      <a href="https://about.meta.com/realitylabs/"><strong>Austin James</strong></a>
      <br>
      <a href="https://www.linkedin.com/in/peter-selednik-05036499/"><strong>Peter Selednik</strong></a>
      .
      <a href="https://scholar.google.fr/citations?user=8orqBsYAAAAJ&hl=ja"><strong>Stuart Anderson</strong></a>
      .
      <a href="https://shunsukesaito.github.io/"><strong>Shunsuke Saito</strong></a>
   </p>
   <h3 align="center">ECCV 2024 - Best Paper Candidate</h3>
</p>

<p align="center">
   <a href='https://about.meta.com/realitylabs/codecavatars/sapiens/'>
      <img src='https://img.shields.io/badge/Sapiens-Page-azure?style=for-the-badge&logo=Google%20chrome&logoColor=white&labelColor=000080&color=007FFF' alt='Project Page'>
   </a>

   <a href="https://arxiv.org/abs/2408.12569">
      <img src='https://img.shields.io/badge/Paper-PDF-green?style=for-the-badge&logo=adobeacrobatreader&logoWidth=20&logoColor=white&labelColor=66cc00&color=94DD15' alt='Paper PDF'>
   </a>

   <a href='https://huggingface.co/collections/facebook/sapiens-66d22047daa6402d565cb2fc'>
      <img src='https://img.shields.io/badge/HuggingFace-Demo-orange?style=for-the-badge&logo=huggingface&logoColor=white&labelColor=FF5500&color=orange' alt='Spaces'>
   </a>

   <a href='https://rawalkhirodkar.github.io/sapiens/'>
      <img src='https://img.shields.io/badge/More-Results-ffffff?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0id2hpdGUiIHdpZHRoPSIxOCIgaGVpZ2h0PSIxOCI+PHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGQ9Ik0xOSAzSDVjLTEuMSAwLTIgLjktMiAydjE0YzAgMS4xLjkgMiAyIDJoMTRjMS4xIDAgMi0uOSAyLTJWNWMwLTEuMS0uOS0yLTItMnpNOSAxN0g3di01aDJ2NXptNCAwaC0ydi03aDJ2N3ptNCAwaC0yVjhoMnY5eiIvPjwvc3ZnPg==&logoColor=white&labelColor=8A2BE2&color=9370DB' alt='Results'>
   </a>
</p>

Sapiens offers a comprehensive suite for human-centric vision tasks (e.g., 2D pose, part segmentation, depth, normal, etc.). The model family is pretrained on 300 million in-the-wild human images and shows excellent generalization to unconstrained conditions. These models are also designed for extracting high-resolution features, having been natively trained at a 1024 x 1024 image resolution with a 16-pixel patch size.

<p align="center">
  <img src="./assets/01.gif" alt="01" title="01" width="400"/>
  <img src="./assets/03.gif" alt="03" title="03" width="400"/>
</p>
<p align="center">
  <img src="./assets/02.gif" alt="02" title="02" width="400"/>
  <img src="./assets/04.gif" alt="04" title="04" width="400"/>
</p>


## ğŸš€ Getting Started

### Clone the Repository
   ```bash
   git clone https://github.com/facebookresearch/sapiens.git
   export SAPIENS_ROOT=/path/to/sapiens
   ```

### Recommended: Lite Installation (Inference-only)
   For users setting up their own environment primarily for running existing models in inference mode, we recommend the [Sapiens-Lite installation](lite/README.md).\
   This setup offers optimized inference (4x faster) with minimal dependencies (only PyTorch + numpy + cv2).

### Full Installation
   To replicate our complete training setup, run the provided installation script. \
   This will create a new conda environment named `sapiens` and install all necessary dependencies.

   ```bash
   cd $SAPIENS_ROOT/_install
   ./conda.sh
   ```

   Please download the **original** checkpoints from [hugging-face](https://huggingface.co/facebook/sapiens). \
   You can be selective about only downloading the checkpoints of interest.\
   Set `$SAPIENS_CHECKPOINT_ROOT` to be the path to the `sapiens_host` folder. Place the checkpoints following this directory structure:
   ```plaintext
   sapiens_host/
   â”œâ”€â”€ detector/
   â”‚   â””â”€â”€ checkpoints/
   â”‚       â””â”€â”€ rtmpose/
   â”œâ”€â”€ pretrain/
   â”‚   â””â”€â”€ checkpoints/
   â”‚       â”œâ”€â”€ sapiens_0.3b/
               â”œâ”€â”€ sapiens_0.3b_epoch_1600_clean.pth
   â”‚       â”œâ”€â”€ sapiens_0.6b/
               â”œâ”€â”€ sapiens_0.6b_epoch_1600_clean.pth
   â”‚       â”œâ”€â”€ sapiens_1b/
   â”‚       â””â”€â”€ sapiens_2b/
   â”œâ”€â”€ pose/
      â””â”€â”€ checkpoints/
         â”œâ”€â”€ sapiens_0.3b/
   â””â”€â”€ seg/
   â””â”€â”€ depth/
   â””â”€â”€ normal/
   ```

## ğŸŒŸ Human-Centric Vision Tasks
We finetune sapiens for multiple human-centric vision tasks. Please checkout the list below.

- ###  [Image Encoder](docs/PRETRAIN_README.md) <sup><small><a href="lite/docs/PRETRAIN_README.md" style="color: #FFA500;">[lite]</a></small></sup>
- ### [Pose Estimation](docs/POSE_README.md) <sup><small><a href="lite/docs/POSE_README.md" style="color: #FFA500;">[lite]</a></small></sup>
- ### [Body Part Segmentation](docs/SEG_README.md) <sup><small><a href="lite/docs/SEG_README.md" style="color: #FFA500;">[lite]</a></small></sup>
- ### [Depth Estimation](docs/DEPTH_README.md) <sup><small><a href="lite/docs/DEPTH_README.md" style="color: #FFA500;">[lite]</a></small></sup>
- ### [Surface Normal Estimation](docs/NORMAL_README.md) <sup><small><a href="lite/docs/NORMAL_README.md" style="color: #FFA500;">[lite]</a></small></sup>

## ğŸ¯ Easy Steps to Finetuning Sapiens
Finetuning our models is super-easy! Here is a detailed training guide for the following tasks.
- ### [Pose Estimation](docs/finetune/POSE_README.md)
- ### [Body-Part Segmentation](docs/finetune/SEG_README.md)
- ### [Depth Estimation](docs/finetune/DEPTH_README.md)
- ### [Surface Normal Estimation](docs/finetune/NORMAL_README.md)

## ğŸ“ˆ Quantitative Evaluations
- ### [Pose Estimation](docs/evaluate/POSE_README.md)

## ğŸ¤ Acknowledgements & Support & Contributing
We would like to acknowledge the work by [OpenMMLab](https://github.com/open-mmlab) which this project benefits from.\
For any questions or issues, please open an issue in the repository.\
See [contributing](CONTRIBUTING.md) and the [code of conduct](CODE_OF_CONDUCT.md).

## License
This project is licensed under [LICENSE](LICENSE).\
Portions derived from open-source projects are licensed under [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0).

## ğŸ“š Citation
If you use Sapiens in your research, please consider citing us.
```bibtex
@article{khirodkar2024sapiens,
  title={Sapiens: Foundation for Human Vision Models},
  author={Khirodkar, Rawal and Bagautdinov, Timur and Martinez, Julieta and Zhaoen, Su and James, Austin and Selednik, Peter and Anderson, Stuart and Saito, Shunsuke},
  journal={arXiv preprint arXiv:2408.12569},
  year={2024}
}
```
-->

# Capstone 2 í”„ë¡œì íŠ¸
# ğŸ§  Human Part Segmentation ê¸°ë°˜ ëˆˆë°”ë”” ë°ì´í„°í™” í”„ë¡œì íŠ¸

ë³¸ í”„ë¡œì íŠ¸ëŠ” ì¸ì²´ ë¶€ìœ„ ë¶„í• (Human Part Segmentation) ë° ìì„¸ ì¶”ì •(Pose Estimation) ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ê°œì¸ì˜ ì‹ ì²´ ë³€í™”ë¥¼ ìë™ìœ¼ë¡œ ì‹œê°í™”í•˜ê³  ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì „ì‹  ì •ë©´ ì‚¬ì§„ì„ ì—…ë¡œë“œí•¨ìœ¼ë¡œì¨ ìì‹ ì˜ ì‹ ì²´ ë°ì´í„°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•˜ê³  ë³€í™” ì¶”ì´ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

- **ëª©í‘œ**: ëˆˆë°”ë””(Body-check) ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ ì‹ ì²´ ë¶€ìœ„ë³„ ë³€í™”ë¥¼ ìë™ ì¶”ì¶œí•˜ê³ , GIF ë“±ìœ¼ë¡œ ì‹œê°í™”í•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ í”¼ë“œë°± ë°›ì„ ìˆ˜ ìˆë„ë¡ ì§€ì›
- **í•µì‹¬ ê¸°ëŠ¥**
  - SAPIE ê¸°ë°˜ ì¸ì²´ ë¶„í• 
  - Detectron2ë¥¼ í™œìš©í•œ í¬ì¦ˆ ì¶”ì •
  - ë¶€ìœ„ë³„ ë©´ì  ê³„ì‚°ì„ í†µí•œ ë³€í™” ì¶”ì •
  - GIF ìƒì„± ë° ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
- **ì‚¬ìš©ì íë¦„**
  1. ì •ë©´ ì „ì‹  ì‚¬ì§„ ì—…ë¡œë“œ
  2. ì¸ì²´ ë¶€ìœ„ ë¶„í•  ë° í¬ì¦ˆ ì¶”ì •
  3. ë¶€ìœ„ë³„ ë©´ì  ê³„ì‚° ë° ì‹œê°í™”
  4. ê²°ê³¼ ì´ë¯¸ì§€ ë° GIF ì €ì¥/í™•ì¸

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

capstone2/
â”‚
â”œâ”€â”€ input_image/ # ì‚¬ìš©ì ì—…ë¡œë“œ ì´ë¯¸ì§€ í´ë”
â”œâ”€â”€ output_image/ # ì²˜ë¦¬ëœ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ í´ë”
â”œâ”€â”€ seg/ # SAPIE ê¸°ë°˜ ë¶„í•  ëª¨ë“ˆ
â”œâ”€â”€ pose/ # Detectron2 ê¸°ë°˜ í¬ì¦ˆ ì¶”ì • ëª¨ë“ˆ
â”œâ”€â”€ estimate_muscle/ # ê·¼ìœ¡ëŸ‰ ê³„ì‚° ê´€ë ¨ ì½”ë“œ
â”œâ”€â”€ demo/ # ë°ëª¨ ì‹¤í–‰ ìƒ˜í”Œ
â”œâ”€â”€ docs/ # ë³´ê³ ì„œ ë“± ë¬¸ì„œ ìë£Œ
â”œâ”€â”€ image_resize.py # ì´ë¯¸ì§€ í¬ê¸° ì •ê·œí™” ìœ í‹¸
â”œâ”€â”€ make_gif.py # ê²°ê³¼ ì´ë¯¸ì§€ ê¸°ë°˜ GIF ìƒì„±ê¸°
â”œâ”€â”€ game.py # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ì½˜ì†” ê¸°ë°˜)
â”œâ”€â”€ server.py # Flask ê¸°ë°˜ ì›¹ ì„œë²„ ì‹¤í–‰ íŒŒì¼
â””â”€â”€ output.gif # ìµœì¢… ë¹„êµ ê²°ê³¼ë¥¼ ë‹´ì€ GIF íŒŒì¼